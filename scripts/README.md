Each experiment I performed with DINOv2+CLIP and DINOv2+SD is here in one of the corresponding jupyter notebooks.
For ease of use I ran each notebook in google colab, so if these notebooks are not run in google colab, then there
might be some dependancy problems that the user will need to resolve(to make sure each library imported is included).

The best performing experiment is in the DINOv2+CLIP_FULL_KPMask_Species_Similarity.ipynb file and it comes from the 
list generated by the KNN metric.

For creating a dataset to train and test an RTMPose model on to evaluate the AP and AR of using lists generated by the DINOv2+CLIP or DINOv2+SD features, it is a multi-step process.

All of the following steps were done on the deadcat server and so they will all be in reference to how the files are structured there:
1. In this Scripts folder find the annotation_parser_ap10k_DINO+CLIP.py file and change the animal_categories list ot the list of similar species to antelopes you generated from whichever metric you were using. Also, change the "ADD_NAME" part of the data_root variable to a descriptive name for whatever you want the folder containing your data and annotations to be named. Then, if you want to change the max_allowed_annotations, there is a variable to do so. It is currently set to be close to the number of annotations used to train the models from the Centroid and Limb Ratio metrics.
2. Run the annotation_parser_ap10k_DINO+CLIP.py file. It will generated a list in your local directory with a properly structured(AP10k format) folder with with the appropriate data and annotations. 
3. The last thing to do before you can run the training and testing scripts described in the top-level README of this repository is to copy the rtmpose-m_8xb64-210e_ap10k-256x256-subset_ADD_NAME.py file into the folder that was just created by the annotation_parser_ap10k_DINO+CLIP.py file and then change the "ADD_NAME" part to match whatever you changed the previous "ADD_NAME" part of the data_root to. Then go into the rtmpose-m_8xb64-210e_ap10k-256x256-subset_ADD_NAME.py file and for each data_root variable that looks like this: data_root='filtered_ap10k_ADD_NAME/', change the "ADD_NAME" portion to match what each other "ADD_NAME" portion was changed to.

Now you can run the training and testing scripts described in the top-level README to train and test an RTMPose model off of this subset of the AP10k dataset and test on all the antelope images in AP-10k.

Training command(following the format provided above):
Change the "ADD_NAME" portions to match the above alterations.

python /home/vip24_shared/mmpose/tools/train.py /home/vip24_shared/mmpose/filtered_ap10k_ADD_NAME/rtmpose-m_8xb64-210e_ap10k-256x256-subset_ADD_NAME.py


Testing command(following the format provided above):
Change the "ADD_NAME" portions to match the above alterations and look in the work_dirs folder in your local directory to find the folder with the training information for the model you trained to find the best epoch number and then fill that portion in as well.

python tools/test.py /home/vip24_shared/mmpose/filtered_ap10k_ADD_NAME/rtmpose-m_8xb64-210e_ap10k-256x256-subset_ADD_NAME.py /home/vip24_shared/mmpose/work_dirs/rtmpose-m_8xb64-210e_ap10k-256x256-subset_ADD_NAME/best_coco_AP_epoch_{BEST_EPOCH NUM}.pth